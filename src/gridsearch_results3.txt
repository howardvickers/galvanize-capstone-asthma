In [44]: pwd
Out[44]: '/Users/howard/workspace/dsi/capstone/capstone_repo/data'

In [45]: cd ..
/Users/howard/workspace/dsi/capstone/capstone_repo

In [46]: ls
README.md    data/        description/ old_files/   src/

In [47]: cd src/
/Users/howard/workspace/dsi/capstone/capstone_repo/src

In [48]: ls
__pycache__/                      data.py                           models.py                         support_vector_regressor.py
ca_data.py                        fl_data.py                        nj.svg                            us_data.py
co_data.py                        k_nearest_neighbors_regressor.py  nj_data.py
color_map.py                      linear_regression.py              random_forest.py
combine_data.py                   logistic_regression.py            random_forest2.py

In [49]: run models.py
/Users/howard/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.
  from pandas.core import datetools
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.
  "This module will be removed in 0.20.", DeprecationWarning)
/Users/howard/workspace/dsi/capstone/capstone_repo/src/data.py:194: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.
  asthma_pollutants = join_side_by_side(state)
r2 score: 0.084843906754
mse: 520.202906606
********************
best params: {}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 17.172
MAPE: inf
Accuracy = -inf%
RMSE (test): 22.8079570897
RMSE (train): 18.6330021118
Overfit
####################
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    135     data.to_csv(csv_file_path)
    136
--> 137     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
     98         clf = GridSearchCV(pipeline, hyperparameters, cv=3) # cv=3 is same as cv=None (default)
     99
--> 100         clf.fit(X_train, y_train)
    101
    102         # evaluate models with test data

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self, X, y, groups, **fit_params)
    637                                   error_score=self.error_score)
    638           for parameters, (train, test) in product(candidate_params,
--> 639                                                    cv.split(X, y, groups)))
    640
    641         # if one choose to see train score, "out" will contain train score info

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    777             # was dispatched. In particular this covers the edge
    778             # case of Parallel used with an exhausted iterator.
--> 779             while self.dispatch_one_batch(iterator):
    780                 self._iterating = True
    781             else:

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self, iterator)
    623                 return False
    624             else:
--> 625                 self._dispatch(tasks)
    626                 return True
    627

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self, batch)
    586         dispatch_timestamp = time.time()
    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
--> 588         job = self._backend.apply_async(batch, callback=cb)
    589         self._jobs.append(job)
    590

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self, func, callback)
    109     def apply_async(self, func, callback=None):
    110         """Schedule a func to be run"""
--> 111         result = ImmediateResult(func)
    112         if callback:
    113             callback(result)

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self, batch)
    330         # Don't delay the application, to avoid keeping the input
    331         # arguments in memory
--> 332         self.results = batch()
    333
    334     def get(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)
    442     train_scores = {}
    443     if parameters is not None:
--> 444         estimator.set_params(**parameters)
    445
    446     start_time = time.time()

~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self, **kwargs)
    140         self
    141         """
--> 142         self._set_params('steps', **kwargs)
    143         return self
    144

~/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self, attr, **params)
     47                 self._replace_estimator(attr, name, params.pop(name))
     48         # 3. Step parameters and other initilisation arguments
---> 49         super(_BaseComposition, self).set_params(**params)
     50         return self
     51

~/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self, **params)
    272                                  'Check the list of available parameters '
    273                                  'with `estimator.get_params().keys()`.' %
--> 274                                  (key, self))
    275
    276             if delim:

ValueError: Invalid parameter en for estimator Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.

In [50]: run models.py
/Users/howard/workspace/dsi/capstone/capstone_repo/src/data.py:194: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.
  asthma_pollutants = join_side_by_side(state)
r2 score: 0.084843906754
mse: 520.202906606
********************
best params: {}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 17.172
MAPE: inf
Accuracy = -inf%
RMSE (test): 22.8079570897
RMSE (train): 18.6330021118
Overfit
####################
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
r2 score: 0.30597492438
mse: 394.505226222
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 17.100
MAPE: inf
Accuracy = -inf%
RMSE (test): 19.8621556288
RMSE (train): 19.9171255207
Underfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.519
Model:                            OLS   Adj. R-squared:                  0.453
Method:                 Least Squares   F-statistic:                     7.868
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           5.86e-15
Time:                        08:09:41   Log-Likelihood:                -725.43
No. Observations:                 167   AIC:                             1493.
Df Residuals:                     146   BIC:                             1558.
Df Model:                          20
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              48.8629     13.886      3.519      0.001      21.419      76.307
pm10_mean           0.7296      0.199      3.669      0.000       0.337       1.123
pm25_mean          -0.0163      0.912     -0.018      0.986      -1.819       1.787
pm25non_mean       -0.5382      0.485     -1.109      0.269      -1.498       0.421
pm25spec_mean      -0.0195      0.019     -1.011      0.313      -0.058       0.019
co_mean            33.0867     21.787      1.519      0.131      -9.972      76.145
so2_mean            3.5541      5.651      0.629      0.530      -7.614      14.722
no2_mean           -1.1394      2.270     -0.502      0.616      -5.625       3.346
ozo_mean          -70.7155    120.591     -0.586      0.559    -309.045     167.614
nonox_mean          0.8517      1.701      0.501      0.617      -2.510       4.214
lead_mean         -43.8523    355.030     -0.124      0.902    -745.514     657.809
haps_mean         -11.7073      7.120     -1.644      0.102     -25.779       2.364
vocs_mean           0.8473      0.315      2.686      0.008       0.224       1.471
smoke_adult         0.7264      0.868      0.837      0.404      -0.989       2.442
obese_adult        -1.3731      0.510     -2.693      0.008      -2.381      -0.365
uninsured          -2.7059      0.452     -5.990      0.000      -3.599      -1.813
pcp                -0.0779      0.068     -1.150      0.252      -0.212       0.056
high_sch_grad      -0.1797      0.063     -2.853      0.005      -0.304      -0.055
unemployment        6.2186      1.099      5.660      0.000       4.047       8.390
income_ineq         6.5659      2.894      2.269      0.025       0.846      12.286
air_poll_partic    -0.0054      1.264     -0.004      0.997      -2.503       2.492
==============================================================================
Omnibus:                        6.180   Durbin-Watson:                   2.036
Prob(Omnibus):                  0.046   Jarque-Bera (JB):                5.979
Skew:                           0.460   Prob(JB):                       0.0503
Kurtosis:                       3.117   Cond. No.                     3.52e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.52e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

In [51]: run models.py
  File "/Users/howard/workspace/dsi/capstone/capstone_repo/src/models.py", line 75
    'gradientboostingregressor__learning_rate': [ 0.01],
                                             ^
SyntaxError: invalid syntax


In [52]: run models.py
  File "/Users/howard/workspace/dsi/capstone/capstone_repo/src/models.py", line 75
    'gradientboostingregressor__learning_rate':     [0.01, 0.1],
                                             ^
SyntaxError: invalid syntax


In [53]: run models.py
  File "/Users/howard/workspace/dsi/capstone/capstone_repo/src/models.py", line 75
    'gbm__learning_rate':     [0.01, 0.1],
                       ^
SyntaxError: invalid syntax


In [54]: run models.py
/Users/howard/workspace/dsi/capstone/capstone_repo/src/data.py:194: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.
  asthma_pollutants = join_side_by_side(state)
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    139     data.to_csv(csv_file_path)
    140
--> 141     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    102         clf = GridSearchCV(pipeline, hyperparameters, cv=3) # cv=3 is same as cv=None (default)
    103
--> 104         clf.fit(X_train, y_train)
    105
    106         # evaluate models with test data

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self, X, y, groups, **fit_params)
    637                                   error_score=self.error_score)
    638           for parameters, (train, test) in product(candidate_params,
--> 639                                                    cv.split(X, y, groups)))
    640
    641         # if one choose to see train score, "out" will contain train score info

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    777             # was dispatched. In particular this covers the edge
    778             # case of Parallel used with an exhausted iterator.
--> 779             while self.dispatch_one_batch(iterator):
    780                 self._iterating = True
    781             else:

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self, iterator)
    623                 return False
    624             else:
--> 625                 self._dispatch(tasks)
    626                 return True
    627

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self, batch)
    586         dispatch_timestamp = time.time()
    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
--> 588         job = self._backend.apply_async(batch, callback=cb)
    589         self._jobs.append(job)
    590

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self, func, callback)
    109     def apply_async(self, func, callback=None):
    110         """Schedule a func to be run"""
--> 111         result = ImmediateResult(func)
    112         if callback:
    113             callback(result)

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self, batch)
    330         # Don't delay the application, to avoid keeping the input
    331         # arguments in memory
--> 332         self.results = batch()
    333
    334     def get(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)
    442     train_scores = {}
    443     if parameters is not None:
--> 444         estimator.set_params(**parameters)
    445
    446     start_time = time.time()

~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in set_params(self, **kwargs)
    140         self
    141         """
--> 142         self._set_params('steps', **kwargs)
    143         return self
    144

~/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _set_params(self, attr, **params)
     47                 self._replace_estimator(attr, name, params.pop(name))
     48         # 3. Step parameters and other initilisation arguments
---> 49         super(_BaseComposition, self).set_params(**params)
     50         return self
     51

~/anaconda3/lib/python3.6/site-packages/sklearn/base.py in set_params(self, **params)
    272                                  'Check the list of available parameters '
    273                                  'with `estimator.get_params().keys()`.' %
--> 274                                  (key, self))
    275
    276             if delim:

ValueError: Invalid parameter gbm for estimator Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, mi...s=100, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))]). Check the list of available parameters with `estimator.get_params().keys()`.

In [55]: run models.py
/Users/howard/workspace/dsi/capstone/capstone_repo/src/data.py:194: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.
  asthma_pollutants = join_side_by_side(state)
r2 score: 0.505337718055
mse: 281.181274708
********************
best params: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'ls', 'gradientboostingregressor__max_depth': 5, 'gradientboostingregressor__min_samples_split': 2, 'gradientboostingregressor__n_estimators': 500}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.01, loss='ls', max_depth=5, max_features=None,
             max_leaf_nodes=None, m...s=500, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 11.666
MAPE: inf
Accuracy = -inf%
RMSE (test): 16.7684607137
RMSE (train): 2.03995276035
Overfit
####################
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
r2 score: 0.30597492438
mse: 394.505226222
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 17.100
MAPE: inf
Accuracy = -inf%
RMSE (test): 19.8621556288
RMSE (train): 19.9171255207
Underfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.519
Model:                            OLS   Adj. R-squared:                  0.453
Method:                 Least Squares   F-statistic:                     7.868
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           5.86e-15
Time:                        09:23:08   Log-Likelihood:                -725.43
No. Observations:                 167   AIC:                             1493.
Df Residuals:                     146   BIC:                             1558.
Df Model:                          20
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              48.8629     13.886      3.519      0.001      21.419      76.307
pm10_mean           0.7296      0.199      3.669      0.000       0.337       1.123
pm25_mean          -0.0163      0.912     -0.018      0.986      -1.819       1.787
pm25non_mean       -0.5382      0.485     -1.109      0.269      -1.498       0.421
pm25spec_mean      -0.0195      0.019     -1.011      0.313      -0.058       0.019
co_mean            33.0867     21.787      1.519      0.131      -9.972      76.145
so2_mean            3.5541      5.651      0.629      0.530      -7.614      14.722
no2_mean           -1.1394      2.270     -0.502      0.616      -5.625       3.346
ozo_mean          -70.7155    120.591     -0.586      0.559    -309.045     167.614
nonox_mean          0.8517      1.701      0.501      0.617      -2.510       4.214
lead_mean         -43.8523    355.030     -0.124      0.902    -745.514     657.809
haps_mean         -11.7073      7.120     -1.644      0.102     -25.779       2.364
vocs_mean           0.8473      0.315      2.686      0.008       0.224       1.471
smoke_adult         0.7264      0.868      0.837      0.404      -0.989       2.442
obese_adult        -1.3731      0.510     -2.693      0.008      -2.381      -0.365
uninsured          -2.7059      0.452     -5.990      0.000      -3.599      -1.813
pcp                -0.0779      0.068     -1.150      0.252      -0.212       0.056
high_sch_grad      -0.1797      0.063     -2.853      0.005      -0.304      -0.055
unemployment        6.2186      1.099      5.660      0.000       4.047       8.390
income_ineq         6.5659      2.894      2.269      0.025       0.846      12.286
air_poll_partic    -0.0054      1.264     -0.004      0.997      -2.503       2.492
==============================================================================
Omnibus:                        6.180   Durbin-Watson:                   2.036
Prob(Omnibus):                  0.046   Jarque-Bera (JB):                5.979
Skew:                           0.460   Prob(JB):                       0.0503
Kurtosis:                       3.117   Cond. No.                     3.52e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.52e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

In [56]: run models.py
/Users/howard/workspace/dsi/capstone/capstone_repo/src/data.py:194: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.
  asthma_pollutants = join_side_by_side(state)
r2 score: 0.457406802118
mse: 308.42668341
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 12.988
MAPE: inf
Accuracy = -inf%
RMSE (test): 17.5620808394
RMSE (train): 12.9992851246
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.519
Model:                            OLS   Adj. R-squared:                  0.453
Method:                 Least Squares   F-statistic:                     7.868
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           5.86e-15
Time:                        09:36:04   Log-Likelihood:                -725.43
No. Observations:                 167   AIC:                             1493.
Df Residuals:                     146   BIC:                             1558.
Df Model:                          20
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              48.8629     13.886      3.519      0.001      21.419      76.307
pm10_mean           0.7296      0.199      3.669      0.000       0.337       1.123
pm25_mean          -0.0163      0.912     -0.018      0.986      -1.819       1.787
pm25non_mean       -0.5382      0.485     -1.109      0.269      -1.498       0.421
pm25spec_mean      -0.0195      0.019     -1.011      0.313      -0.058       0.019
co_mean            33.0867     21.787      1.519      0.131      -9.972      76.145
so2_mean            3.5541      5.651      0.629      0.530      -7.614      14.722
no2_mean           -1.1394      2.270     -0.502      0.616      -5.625       3.346
ozo_mean          -70.7155    120.591     -0.586      0.559    -309.045     167.614
nonox_mean          0.8517      1.701      0.501      0.617      -2.510       4.214
lead_mean         -43.8523    355.030     -0.124      0.902    -745.514     657.809
haps_mean         -11.7073      7.120     -1.644      0.102     -25.779       2.364
vocs_mean           0.8473      0.315      2.686      0.008       0.224       1.471
smoke_adult         0.7264      0.868      0.837      0.404      -0.989       2.442
obese_adult        -1.3731      0.510     -2.693      0.008      -2.381      -0.365
uninsured          -2.7059      0.452     -5.990      0.000      -3.599      -1.813
pcp                -0.0779      0.068     -1.150      0.252      -0.212       0.056
high_sch_grad      -0.1797      0.063     -2.853      0.005      -0.304      -0.055
unemployment        6.2186      1.099      5.660      0.000       4.047       8.390
income_ineq         6.5659      2.894      2.269      0.025       0.846      12.286
air_poll_partic    -0.0054      1.264     -0.004      0.997      -2.503       2.492
==============================================================================
Omnibus:                        6.180   Durbin-Watson:                   2.036
Prob(Omnibus):                  0.046   Jarque-Bera (JB):                5.979
Skew:                           0.460   Prob(JB):                       0.0503
Kurtosis:                       3.117   Cond. No.                     3.52e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.52e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    147     # data.to_csv(csv_file_path)
    148
--> 149     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    123     # fit random forest with best parameters to generate feature importances
    124     mod = RFR(best_params_dict[RFR])
--> 125     mod.fit(X_train, y_train)
    126     mod.predict(X_test)
    127     print(mod.feature_importances_)

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in fit(self, X, y, sample_weight)
    283
    284         # Check parameters
--> 285         self._validate_estimator()
    286
    287         if not self.bootstrap and self.oob_score:

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/base.py in _validate_estimator(self, default)
    103         if not isinstance(self.n_estimators, (numbers.Integral, np.integer)):
    104             raise ValueError("n_estimators must be an integer, "
--> 105                              "got {0}.".format(type(self.n_estimators)))
    106
    107         if self.n_estimators <= 0:

ValueError: n_estimators must be an integer, got <class 'dict'>.

In [57]: run models.py
Data file found, loading data...
r2 score: 0.795960513759
mse: 115.982327592
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.424
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.7695091621
RMSE (train): 7.2942393387
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        09:38:15   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    149     # data.to_csv(csv_file_path)
    150
--> 151     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    124     # for k,v in best_params_dict.items():
    125
--> 126     mod = RFR(best_params_dict[0])
    127     mod.fit(X_train, y_train)
    128     mod.predict(X_test)

KeyError: 0

In [58]: run models.py
Data file found, loading data...
r2 score: 0.81716632612
mse: 103.928290791
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 6.999
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.1945225877
RMSE (train): 6.98174882397
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        09:38:25   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    149     # data.to_csv(csv_file_path)
    150
--> 151     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    124     # for k,v in best_params_dict.items():
    125
--> 126     mod = RFR(best_params_dict[1])
    127     mod.fit(X_train, y_train)
    128     mod.predict(X_test)

KeyError: 1

In [59]: abc = { 'svr__kernel': ['linear'],
    ...:                                 'svr__C': [10]
    ...:                                 }
    ...:

In [60]: abc
Out[60]: {'svr__C': [10], 'svr__kernel': ['linear']}

In [61]: abc[0]
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-61-1758867569d8> in <module>()
----> 1 abc[0]

KeyError: 0

In [62]: abc.items()
Out[62]: dict_items([('svr__kernel', ['linear']), ('svr__C', [10])])

In [63]: new_list = []
    ...: for k,v in abc.items():
    ...:     new_list.append(k:v)
  File "<ipython-input-63-02a137c3b722>", line 3
    new_list.append(k:v)
                     ^
SyntaxError: invalid syntax


In [64]: new_list = []
    ...: for k,v in abc.items():
    ...:     new_list.append(k,v)
    ...:
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-64-03ad2a4a246f> in <module>()
      1 new_list = []
      2 for k,v in abc.items():
----> 3     new_list.append(k,v)
      4

TypeError: append() takes exactly one argument (2 given)

In [65]: list(abc)
Out[65]: ['svr__kernel', 'svr__C']

In [66]: for k, v in abc.items():
    ...:     print(k.strip('__'))
    ...:
svr__kernel
svr__C

In [67]: for k, v in abc.items():
    ...:     print(k.strip('svr__'))
    ...:
kernel
C

In [68]: for k, v in abc.items():
    ...:     print(k.strbest_params_dictip('svr__'))
    ...:
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-68-77832ee39a91> in <module>()
      1 for k, v in abc.items():
----> 2     print(k.strbest_params_dictip('svr__'))
      3

AttributeError: 'str' object has no attribute 'strbest_params_dictip'

In [69]: best_params_dict = { 'randomforestregressor__max_features' : ['auto' ],
    ...:                                 'randomforestregressor__max_depth': [None, 5],
    ...:                                 'randomforestregressor__bootstrap': [True],
    ...:                                 'randomforestregressor__min_samples_leaf': [ 5],
    ...:                                 'randomforestregressor__min_samples_split': [10],
    ...:                                 }
    ...:

In [70]: best_params_dict
Out[70]:
{'randomforestregressor__bootstrap': [True],
 'randomforestregressor__max_depth': [None, 5],
 'randomforestregressor__max_features': ['auto'],
 'randomforestregressor__min_samples_leaf': [5],
 'randomforestregressor__min_samples_split': [10]}

In [71]:     param_list = []
    ...:     for k,v in best_params_dict.items():
    ...:         k = k.strip('randomforestregressor__')
    ...:         param_list.append(k=v)
    ...:     print(param_list)
    ...:
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-71-28120f4e837a> in <module>()
      2 for k,v in best_params_dict.items():
      3     k = k.strip('randomforestregressor__')
----> 4     param_list.append(k=v)
      5 print(param_list)

TypeError: append() takes no keyword arguments

In [72]:     param_list = []
    ...:     for k,v in best_params_dict.items():
    ...:         k = k.strip('randomforestregressor__')
    ...:         param_list.append(v)
    ...:     print(param_list)
    ...:
    ...:
[['auto'], [None, 5], [True], [5], [10]]

In [73]: run models.py
Data file found, loading data...
r2 score: 0.764095751029
mse: 134.095240037
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.823
MAPE: inf
Accuracy = -inf%
RMSE (test): 11.5799499151
RMSE (train): 7.57688715987
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        10:33:35   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    158     # data.to_csv(csv_file_path)
    159
--> 160     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    124     param_list = []
    125     for k,v in best_params_dict.items():
--> 126         k = k.strip('randomforestregressor__')
    127         param_list.append(v)
    128     print(param_list)

AttributeError: type object 'RandomForestRegressor' has no attribute 'strip'

In [74]: run models.py
Data file found, loading data...
r2 score: 0.786288428682
mse: 121.480238612
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.848
MAPE: inf
Accuracy = -inf%
RMSE (test): 11.0218074113
RMSE (train): 7.46421282259
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        10:33:47   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    158     # data.to_csv(csv_file_path)
    159
--> 160     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    128     # print(param_list)
    129
--> 130     mod = RFR(max_features          = best_params_dict[randomforestregressor__max_features],
    131                 max_depth           = best_params_dict[randomforestregressor__max_depth],
    132                 bootstrap           = best_params_dict[randomforestregressor__bootstrap],

NameError: name 'randomforestregressor__max_features' is not defined

In [75]: run models.py
Data file found, loading data...
r2 score: 0.788784493963
mse: 120.061398238
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.568
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.957253225
RMSE (train): 7.60342765672
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        10:34:11   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    158     # data.to_csv(csv_file_path)
    159
--> 160     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    128     # print(param_list)
    129
--> 130     mod = RFR(max_features          = best_params_dict['randomforestregressor__max_features'],
    131                 max_depth           = best_params_dict['randomforestregressor__max_depth'],
    132                 bootstrap           = best_params_dict['randomforestregressor__bootstrap'],

KeyError: 'randomforestregressor__max_features'

In [76]: abc
Out[76]: {'svr__C': [10], 'svr__kernel': ['linear']}

In [77]: abc['svr__C'] = {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features
    ...: ': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}

In [78]: abc
Out[78]:
{'svr__C': {'randomforestregressor__bootstrap': True,
  'randomforestregressor__max_depth': 5,
  'randomforestregressor__max_features': 'auto',
  'randomforestregressor__min_samples_leaf': 5,
  'randomforestregressor__min_samples_split': 10},
 'svr__kernel': ['linear']}

In [79]: abc['svr__C']['randomforestregressor__bootstrap']
Out[79]: True

In [80]: run models.py
  File "/Users/howard/workspace/dsi/capstone/capstone_repo/src/models.py", line 133
    mod = RFR(  max_features        = best_params_dict['RFR']['randomforestregressor__max_features'],
    ^
IndentationError: unexpected indent


In [81]: run models.py
Data file found, loading data...
r2 score: 0.814024469959
mse: 105.71421859
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.263
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.2817420017
RMSE (train): 7.0987097243
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        10:54:42   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    160     # data.to_csv(csv_file_path)
    161
--> 162     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    130
    131
--> 132     mod = RFR(  max_features        = best_params_dict['RFR']['randomforestregressor__max_features'],
    133                 max_depth           = best_params_dict['RFR']['randomforestregressor__max_depth'],
    134                 bootstrap           = best_params_dict['RFR']['randomforestregressor__bootstrap'],

KeyError: 'RFR'

In [82]: run models.py
Data file found, loading data...
r2 score: 0.785329881186
mse: 122.025106528
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.285
MAPE: inf
Accuracy = -inf%
RMSE (test): 11.0464974779
RMSE (train): 7.12221235335
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        10:55:14   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    160     # data.to_csv(csv_file_path)
    161
--> 162     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    137                 )
    138     mod.fit(X_train, y_train)
--> 139     mod.predict(X_test)
    140     print(mod.feature_importances_)
    141

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [83]: run models.py
Data file found, loading data...
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
r2 score: 0.801543155303
mse: 112.808982215
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.145
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.6211572917
RMSE (train): 7.45965542671
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        10:57:47   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    165     # data.to_csv(csv_file_path)
    166
--> 167     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    142                 )
    143     mod.fit(X_train, y_train)
--> 144     mod.predict(X_test)
    145     print(mod.feature_importances_)
    146

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [84]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
r2 score: 0.801580816364
mse: 112.787574509
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.375
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.6201494579
RMSE (train): 7.1019066271
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:00:46   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {<class 'sklearn.ensemble.forest.RandomForestRegressor'>: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    170     # data.to_csv(csv_file_path)
    171
--> 172     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    147                 )
    148     mod.fit(X_train, y_train)
--> 149     mod.predict(X_test)
    150     print(mod.feature_importances_)
    151

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [85]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
r2 score: 0.828319299216
mse: 97.5885974153
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 6.818
MAPE: inf
Accuracy = -inf%
RMSE (test): 9.87869411488
RMSE (train): 7.61112962958
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:06:32   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {<class 'sklearn.ensemble.forest.RandomForestRegressor'>: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    170     # data.to_csv(csv_file_path)
    171
--> 172     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    147                 )
    148     mod.fit(X_train, y_train)
--> 149     mod.predict(X_test)
    150     print(mod.feature_importances_)
    151

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [86]: run models.py
  File "/Users/howard/workspace/dsi/capstone/capstone_repo/src/models.py", line 142
    mod = RFR(  max_features        = best_params_dict[<class 'sklearn.ensemble.forest.RandomForestRegressor'>]['randomforestregressor__max_features'],
                                                       ^
SyntaxError: invalid syntax


In [87]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
r2 score: 0.800798436085
mse: 113.232303553
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.306
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.6410668428
RMSE (train): 7.49300308717
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:08:13   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {<class 'sklearn.ensemble.forest.RandomForestRegressor'>: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    170     # data.to_csv(csv_file_path)
    171
--> 172     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    140
    141
--> 142     mod = RFR(  max_features        = best_params_dict["<class 'sklearn.ensemble.forest.RandomForestRegressor'>"]['randomforestregressor__max_features'],
    143                 max_depth           = best_params_dict["<class 'sklearn.ensemble.forest.RandomForestRegressor'>"]['randomforestregressor__max_depth'],
    144                 bootstrap           = best_params_dict["<class 'sklearn.ensemble.forest.RandomForestRegressor'>"]['randomforestregressor__bootstrap'],

KeyError: "<class 'sklearn.ensemble.forest.RandomForestRegressor'>"

In [88]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODELMODELMODELMODELMODELMODELMODELMODELMODELMODELMODELMODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
r2 score: 0.817391063886
mse: 103.800542924
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 6.997
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.1882551462
RMSE (train): 6.81619414965
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:09:51   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {<class 'sklearn.ensemble.forest.RandomForestRegressor'>: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    173     # data.to_csv(csv_file_path)
    174
--> 175     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    150                 )
    151     mod.fit(X_train, y_train)
--> 152     mod.predict(X_test)
    153     print(mod.feature_importances_)
    154

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [89]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
r2 score: 0.771784954404
mse: 129.724460041
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.883
MAPE: inf
Accuracy = -inf%
RMSE (test): 11.389664615
RMSE (train): 7.31519518078
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:11:35   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {<class 'sklearn.ensemble.forest.RandomForestRegressor'>: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    175     # data.to_csv(csv_file_path)
    176
--> 177     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    152                 )
    153     mod.fit(X_train, y_train)
--> 154     mod.predict(X_test)
    155     print(mod.feature_importances_)
    156

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [90]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
r2 score: 0.785390638703
mse: 121.990570085
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.489
MAPE: inf
Accuracy = -inf%
RMSE (test): 11.0449341367
RMSE (train): 7.23132467627
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:12:07   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    175     # data.to_csv(csv_file_path)
    176
--> 177     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    145
    146
--> 147     mod = RFR(  max_features        = best_params_dict[RFR]['randomforestregressor__max_features'],
    148                 max_depth           = best_params_dict[RFR]['randomforestregressor__max_depth'],
    149                 bootstrap           = best_params_dict[RFR]['randomforestregressor__bootstrap'],

KeyError: <class 'sklearn.ensemble.forest.RandomForestRegressor'>

In [91]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
r2 score: 0.793837914389
mse: 117.188878442
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.392
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.8253812146
RMSE (train): 7.47501226986
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:12:30   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    175     # data.to_csv(csv_file_path)
    176
--> 177     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    152                 )
    153     mod.fit(X_train, y_train)
--> 154     mod.predict(X_test)
    155     print(mod.feature_importances_)
    156

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [92]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
r2 score: 0.802362769909
mse: 112.343088032
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.430
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.5992022357
RMSE (train): 7.09284850666
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:15:03   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    176     # data.to_csv(csv_file_path)
    177
--> 178     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    153     mod.fit(X_train, y_train)
    154     print(mod.get_params())
--> 155     mod.predict(X_test)
    156     print(mod.feature_importances_)
    157

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [93]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
r2 score: 0.816866216988
mse: 104.098882064
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.167
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.2028859674
RMSE (train): 7.24026536012
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:15:26   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': 5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    177     # data.to_csv(csv_file_path)
    178
--> 179     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    154     print('get_params()'*20)
    155     print(mod.get_params())
--> 156     mod.predict(X_test)
    157     print(mod.feature_importances_)
    158

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [94]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
r2 score: 0.807877988832
mse: 109.208067749
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.150
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.4502663961
RMSE (train): 7.30607909214
Overfit
####################
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': 5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    170     # data.to_csv(csv_file_path)
    171
--> 172     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    147     print('get_params()'*20)
    148     print(mod.get_params())
--> 149     mod.predict(X_test)
    150     print(mod.feature_importances_)
    151

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [95]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
r2 score: 0.814066086002
mse: 105.690562749
********************
best params: {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=5,
           max_features='auto', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=5, min_samples_split=10,
           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 7.232
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.2805915564
RMSE (train): 7.57831088726
Overfit
####################
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.750
Model:                            OLS   Adj. R-squared:                  0.714
Method:                 Least Squares   F-statistic:                     20.72
Date:                Thu, 05 Apr 2018   Prob (F-statistic):           1.22e-33
Time:                        11:19:31   Log-Likelihood:                -670.73
No. Observations:                 167   AIC:                             1385.
Df Residuals:                     145   BIC:                             1454.
Df Model:                          21
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              75.7187     10.307      7.347      0.000      55.348      96.089
Unnamed: 0         -0.3292      0.028    -11.582      0.000      -0.385      -0.273
pm10_mean           0.2356      0.150      1.570      0.118      -0.061       0.532
pm25_mean           1.2480      0.669      1.866      0.064      -0.074       2.570
pm25non_mean       -0.5533      0.351     -1.576      0.117      -1.247       0.141
pm25spec_mean      -0.0092      0.014     -0.662      0.509      -0.037       0.018
co_mean           -15.5152     16.305     -0.952      0.343     -47.742      16.712
so2_mean            6.3063      4.094      1.540      0.126      -1.785      14.397
no2_mean           -0.9738      1.641     -0.593      0.554      -4.218       2.270
ozo_mean          -62.7501     87.213     -0.720      0.473    -235.124     109.624
nonox_mean          0.7114      1.230      0.578      0.564      -1.720       3.143
lead_mean        -152.5879    256.927     -0.594      0.554    -660.394     355.218
haps_mean           7.3223      5.405      1.355      0.178      -3.360      18.005
vocs_mean           0.1231      0.237      0.521      0.603      -0.344       0.591
smoke_adult         1.6231      0.633      2.566      0.011       0.373       2.873
obese_adult        -0.4699      0.377     -1.247      0.215      -1.215       0.275
uninsured          -1.7464      0.337     -5.182      0.000      -2.413      -1.080
pcp                -0.0600      0.049     -1.223      0.223      -0.157       0.037
high_sch_grad      -0.0661      0.047     -1.419      0.158      -0.158       0.026
unemployment        0.8946      0.918      0.975      0.331      -0.920       2.709
income_ineq        -0.1950      2.173     -0.090      0.929      -4.490       4.100
air_poll_partic     1.0147      0.918      1.105      0.271      -0.800       2.830
==============================================================================
Omnibus:                       15.308   Durbin-Watson:                   2.001
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               18.297
Skew:                           0.625   Prob(JB):                     0.000106
Kurtosis:                       4.034   Cond. No.                     4.05e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 4.05e+04. This might indicate that there are
strong multicollinearity or other numerical problems.
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': 5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    170     # data.to_csv(csv_file_path)
    171
--> 172     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    147     print('get_params()'*20)
    148     print(mod.get_params())
--> 149     mod.predict(X_test)
    150     print(mod.feature_importances_)
    151

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [96]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE END SHAPE
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 7.922
MAPE: inf
Accuracy = -inf%
RMSE (test): 11.1524723648
RMSE (train): 7.49835754787
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    169     # data.to_csv(csv_file_path)
    170
--> 171     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    146     print('get_params()'*20)
    147     print(mod.get_params())
--> 148     mod.predict(X_test)
    149     print(mod.feature_importances_)
    150

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [97]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 7.409
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.7511199859
RMSE (train): 7.27084809656
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    168     # data.to_csv(csv_file_path)
    169
--> 170     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    145     print('get_params()'*20)
    146     print(mod.get_params())
--> 147     mod.predict(X_test)
    148     print(mod.feature_importances_)
    149

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [98]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 6.934
MAPE: inf
Accuracy = -inf%
RMSE (test): 9.83449256442
RMSE (train): 7.33019812486
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN
X_train.shape (167, 22)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    177     # data.to_csv(csv_file_path)
    178
--> 179     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    154     print('get_params()'*20)
    155     print(mod.get_params())
--> 156     mod.predict(X_test)
    157     print(mod.feature_importances_)
    158

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [99]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 7.018
MAPE: inf
Accuracy = -inf%
RMSE (test): 9.98846210751
RMSE (train): 7.26576569118
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN AGAIN
X_train.shape (167, 22)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    178     # data.to_csv(csv_file_path)
    179
--> 180     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    155     print('get_params()'*20)
    156     print(mod.get_params())
--> 157     mod.predict(X_test)
    158     print(mod.feature_importances_)
    159

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in predict(self, X)
    679         check_is_fitted(self, 'estimators_')
    680         # Check data
--> 681         X = self._validate_X_predict(X)
    682
    683         # Assign chunk of trees to jobs

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _validate_X_predict(self, X)
    355                                  "call `fit` before exploiting the model.")
    356
--> 357         return self.estimators_[0]._validate_X_predict(X, check_input=True)
    358
    359     @property

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in _validate_X_predict(self, X, check_input)
    382                              "match the input. Model n_features is %s and "
    383                              "input n_features is %s "
--> 384                              % (self.n_features_, n_features))
    385
    386         return X

ValueError: Number of features of the model must match the input. Model n_features is 22 and input n_features is 21

In [100]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 8.381
MAPE: inf
Accuracy = -inf%
RMSE (test): 12.4168062526
RMSE (train): 7.36092996715
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
[  7.41017247e-01   7.13846252e-03   1.85104434e-02   3.43636313e-03
   7.37691506e-03   9.96625325e-05   0.00000000e+00   1.20391387e-03
   1.05844400e-03   4.88661416e-04   0.00000000e+00   5.74290779e-05
   0.00000000e+00   1.19237673e-02   3.99477524e-02   7.34605211e-03
   1.29100144e-02   3.12223953e-03   3.39786638e-03   5.90280910e-03
   1.35061956e-01]

In [101]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 7.425
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.360306176
RMSE (train): 6.74356939994
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
[  7.50472732e-01   2.98007587e-03   2.19971247e-02   4.35664729e-05
   6.38205350e-03   0.00000000e+00   9.67726437e-04   0.00000000e+00
   1.55479824e-03   3.27821281e-03   1.25129519e-03   0.00000000e+00
   0.00000000e+00   1.67077945e-02   4.55541910e-02   2.97930438e-03
   1.65993473e-02   2.34690373e-03   7.02117296e-03   1.13164497e-02
   1.08547251e-01]
[  7.50472732e-01   2.98007587e-03   2.19971247e-02   4.35664729e-05
   6.38205350e-03   0.00000000e+00   9.67726437e-04   0.00000000e+00
   1.55479824e-03   3.27821281e-03   1.25129519e-03   0.00000000e+00
   0.00000000e+00   1.67077945e-02   4.55541910e-02   2.97930438e-03
   1.65993473e-02   2.34690373e-03   7.02117296e-03   1.13164497e-02
   1.08547251e-01]
Index(['Unnamed: 0', 'pm10_mean', 'pm25_mean', 'pm25non_mean', 'pm25spec_mean',
       'co_mean', 'so2_mean', 'no2_mean', 'ozo_mean', 'nonox_mean',
       'lead_mean', 'haps_mean', 'vocs_mean', 'smoke_adult', 'obese_adult',
       'uninsured', 'pcp', 'high_sch_grad', 'unemployment', 'income_ineq',
       'air_poll_partic'],
      dtype='object')

In [102]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 7.309
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.9571548806
RMSE (train): 7.19529834143
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
[  7.36231356e-01   1.62755523e-03   9.69324439e-03   2.65508863e-06
   2.01330411e-03   0.00000000e+00   0.00000000e+00   1.45243572e-03
   1.32390185e-03   2.01505941e-04   0.00000000e+00   9.94484846e-05
   0.00000000e+00   2.31949705e-02   5.67701141e-02   6.14250879e-03
   4.90285765e-03   6.30437893e-03   3.86862600e-03   6.55999243e-03
   1.39611145e-01]
(21,)
(21,)

In [103]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 7.100
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.2427683554
RMSE (train): 7.28965410822
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': 5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
[  7.34719216e-01   6.49380929e-03   1.15390130e-02   1.16331578e-04
   5.20576659e-03   8.70109594e-04   0.00000000e+00   0.00000000e+00
   5.26490453e-05   6.08038484e-04   0.00000000e+00   7.45688052e-04
   0.00000000e+00   7.84299781e-03   5.44107403e-02   7.72041237e-03
   1.14258967e-02   3.17467304e-03   6.80682500e-03   7.85779959e-03
   1.40410034e-01]
(21,)
(21,)
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    184     # data.to_csv(csv_file_path)
    185
--> 186     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    151     print(names.shape)
    152
--> 153     imps, names = zip(*sorted(zip(imp, names)))
    154
    155     plt.barh(range(len(names)), imp, align='center')

NameError: name 'imp' is not defined

In [104]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 7.258
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.1896336939
RMSE (train): 6.77835190848
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': None, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
[  7.55186778e-01   2.25433542e-03   4.32438435e-03   0.00000000e+00
   3.19190952e-03   0.00000000e+00   2.60852337e-03   0.00000000e+00
   6.20445328e-04   1.99785993e-03   0.00000000e+00   5.55186063e-04
   7.90340055e-04   1.00259686e-02   6.40403190e-02   1.35419471e-03
   1.18251166e-02   8.48805715e-03   1.75638471e-03   1.17713239e-02
   1.19208873e-01]
(21,)
(21,)
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    184     # data.to_csv(csv_file_path)
    185
--> 186     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    153     imps, names = zip(*sorted(zip(imps, names)))
    154
--> 155     plt.barh(range(len(names)), imps, align='center')
    156     plt.yticks(range(len(names)), names)
    157     plt.xlabel('feature_importances_')

NameError: name 'plt' is not defined

In [105]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 21)
y_train.shape (167,)
X_test.shape (42, 21)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
Model Performance Indicators
MAE: 7.197
MAPE: inf
Accuracy = -inf%
RMSE (test): 10.4884286683
RMSE (train): 7.56953059446
Overfit
BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS BEST PARAMS
best_params_dict {'rfr': {'randomforestregressor__bootstrap': True, 'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 'auto', 'randomforestregressor__min_samples_leaf': 5, 'randomforestregressor__min_samples_split': 10}}
END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS END PARAMS
get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()get_params()
{'bootstrap': True, 'criterion': 'mse', 'max_depth': 5, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 5, 'min_samples_split': 10, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': 1, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}
[  7.68425902e-01   9.28359609e-03   6.74759840e-03   9.54593575e-04
   1.19150918e-03   0.00000000e+00   7.54866077e-04   5.52905840e-04
   1.77895842e-03   4.96984975e-03   0.00000000e+00   1.02002594e-03
   0.00000000e+00   1.51361781e-02   6.26361139e-02   7.05082704e-03
   8.79444719e-03   4.13601460e-03   2.83823965e-03   9.77639863e-03
   9.39519759e-02]
(21,)
(21,)

In [106]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
^C---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    209     # from data import join_data as data
    210     # data = data()
--> 211     # data.to_csv(csv_file_path, index=False)
    212
    213     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    125         hyperparameters = hyperpara_dict[model]
    126
--> 127         clf = GridSearchCV(pipeline, hyperparameters, cv=3) # cv=3 is same as cv=None (default)
    128
    129         clf.fit(X_train, y_train)

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self, X, y, groups, **fit_params)
    637                                   error_score=self.error_score)
    638           for parameters, (train, test) in product(candidate_params,
--> 639                                                    cv.split(X, y, groups)))
    640
    641         # if one choose to see train score, "out" will contain train score info

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    777             # was dispatched. In particular this covers the edge
    778             # case of Parallel used with an exhausted iterator.
--> 779             while self.dispatch_one_batch(iterator):
    780                 self._iterating = True
    781             else:

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self, iterator)
    623                 return False
    624             else:
--> 625                 self._dispatch(tasks)
    626                 return True
    627

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self, batch)
    586         dispatch_timestamp = time.time()
    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
--> 588         job = self._backend.apply_async(batch, callback=cb)
    589         self._jobs.append(job)
    590

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self, func, callback)
    109     def apply_async(self, func, callback=None):
    110         """Schedule a func to be run"""
--> 111         result = ImmediateResult(func)
    112         if callback:
    113             callback(result)

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self, batch)
    330         # Don't delay the application, to avoid keeping the input
    331         # arguments in memory
--> 332         self.results = batch()
    333
    334     def get(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)
    456             estimator.fit(X_train, **fit_params)
    457         else:
--> 458             estimator.fit(X_train, y_train, **fit_params)
    459
    460     except Exception as e:

~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self, X, y, **fit_params)
    248         Xt, fit_params = self._fit(X, y, **fit_params)
    249         if self._final_estimator is not None:
--> 250             self._final_estimator.fit(Xt, y, **fit_params)
    251         return self
    252

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in fit(self, X, y, sample_weight)
    326                     t, self, X, y, sample_weight, i, len(trees),
    327                     verbose=self.verbose, class_weight=self.class_weight)
--> 328                 for i, t in enumerate(trees))
    329
    330             # Collect newly grown trees

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    777             # was dispatched. In particular this covers the edge
    778             # case of Parallel used with an exhausted iterator.
--> 779             while self.dispatch_one_batch(iterator):
    780                 self._iterating = True
    781             else:

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self, iterator)
    623                 return False
    624             else:
--> 625                 self._dispatch(tasks)
    626                 return True
    627

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self, batch)
    586         dispatch_timestamp = time.time()
    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
--> 588         job = self._backend.apply_async(batch, callback=cb)
    589         self._jobs.append(job)
    590

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self, func, callback)
    109     def apply_async(self, func, callback=None):
    110         """Schedule a func to be run"""
--> 111         result = ImmediateResult(func)
    112         if callback:
    113             callback(result)

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self, batch)
    330         # Don't delay the application, to avoid keeping the input
    331         # arguments in memory
--> 332         self.results = batch()
    333
    334     def get(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py in _parallel_build_trees(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)
    121         tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)
    122     else:
--> 123         tree.fit(X, y, sample_weight=sample_weight, check_input=False)
    124
    125     return tree

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self, X, y, sample_weight, check_input, X_idx_sorted)
   1122             sample_weight=sample_weight,
   1123             check_input=check_input,
-> 1124             X_idx_sorted=X_idx_sorted)
   1125         return self
   1126

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self, X, y, sample_weight, check_input, X_idx_sorted)
    360                                            min_impurity_split)
    361
--> 362         builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)
    363
    364         if self.n_outputs_ == 1:

KeyboardInterrupt:

In [107]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
Model Performance Indicators
MAE: 17.172
MAPE: inf
Accuracy = -inf%
RMSE (test): 22.8079570897
RMSE (train): 18.6330021118
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    211     # data.to_csv(csv_file_path, index=False)
    212
--> 213     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    140         # print('#'*20)
    141
--> 142         best_params_dict[tag] = clf.best_params_
    143         print('BEST PARAMS '*10)
    144

NameError: name 'best_params_dict' is not defined

In [108]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
Model Performance Indicators
MAE: 17.172
MAPE: inf
Accuracy = -inf%
RMSE (test): 22.8079570897
RMSE (train): 18.6330021118
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    211     # data.to_csv(csv_file_path, index=False)
    212
--> 213     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    140         # print('#'*20)
    141
--> 142         best_params_dict[tag] = clf.best_params_
    143     print('BEST PARAMS '*10)
    144

NameError: name 'best_params_dict' is not defined

In [109]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
********************
best params: {}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 17.172
MAPE: inf
Accuracy = -inf%
RMSE (test): 22.8079570897
RMSE (train): 18.6330021118
Overfit
********************
best params: {'randomforestregressor__bootstrap': False, 'randomforestregressor__max_depth': 100, 'randomforestregressor__max_features': 'sqrt', 'randomforestregressor__min_samples_leaf': 1, 'randomforestregressor__min_samples_split': 2, 'randomforestregressor__n_estimators': 200}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('randomforestregressor', RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=100,
           max_features='sqrt', max_leaf_nodes=None,
           min_impurity_decrease=0.0, min_impurity_split=None,
           min_samples_leaf=1, min_samples_split=2,
           min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,
           oob_score=False, random_state=None, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 12.381
MAPE: inf
Accuracy = -inf%
RMSE (test): 16.4097206906
RMSE (train): 1.1372790274e-13
Overfit
********************
best params: {'gradientboostingregressor__learning_rate': 0.01, 'gradientboostingregressor__loss': 'ls', 'gradientboostingregressor__max_depth': 10, 'gradientboostingregressor__min_samples_split': 10, 'gradientboostingregressor__n_estimators': 1000}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.01, loss='ls', max_depth=10,
             max_features=None, max_leaf_nodes=None,
...       presort='auto', random_state=None, subsample=1.0, verbose=0,
             warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 12.835
MAPE: inf
Accuracy = -inf%
RMSE (test): 18.0237386002
RMSE (train): 0.0265432080465
Overfit
********************
best params: {'kneighborsregressor__n_neighbors': 3, 'kneighborsregressor__weights': 'distance'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsregressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
          metric_params=None, n_jobs=1, n_neighbors=3, p=2,
          weights='distance'))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 12.295
MAPE: inf
Accuracy = -inf%
RMSE (test): 17.5735928368
RMSE (train): 0.0
Overfit
********************
best params: {'svr__C': 10, 'svr__epsilon': 1.5, 'svr__kernel': 'rbf'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=1.5, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 14.719
MAPE: inf
Accuracy = -inf%
RMSE (test): 19.144794478
RMSE (train): 16.3821397832
Overfit
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
MAE: 17.100
MAPE: inf
Accuracy = -inf%
RMSE (test): 19.8621556288
RMSE (train): 19.9171255207
Underfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    211     # data.to_csv(csv_file_path, index=False)
    212
--> 213     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    148
    149
--> 150     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    151                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    152                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'best_params_dict' is not defined

In [110]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
********************
best params: {'kneighborsregressor__n_neighbors': 3, 'kneighborsregressor__weights': 'distance'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsregressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
          metric_params=None, n_jobs=1, n_neighbors=3, p=2,
          weights='distance'))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsregressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
          metric_params=None, n_jobs=1, n_neighbors=3, p=2,
          weights='distance'))])
MAE: 12.295
MAPE: inf
Accuracy = -inf%
RMSE (test): 17.5735928368
RMSE (train): 0.0
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    212     # data.to_csv(csv_file_path, index=False)
    213
--> 214     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    149
    150
--> 151     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    152                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    153                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [111]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
********************
best params: {'kneighborsregressor__n_neighbors': 4, 'kneighborsregressor__weights': 'distance'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsregressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
          metric_params=None, n_jobs=1, n_neighbors=4, p=2,
          weights='distance'))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('kneighborsregressor', KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',
          metric_params=None, n_jobs=1, n_neighbors=4, p=2,
          weights='distance'))])
MAE: 11.054
MAPE: inf
Accuracy = -inf%
RMSE (test): 15.6904523376
RMSE (train): 0.0
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    212     # data.to_csv(csv_file_path, index=False)
    213
--> 214     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    149
    150
--> 151     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    152                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    153                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [112]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
********************
best params: {'svr__C': 20, 'svr__epsilon': 2, 'svr__kernel': 'rbf'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=20, cache_size=200, coef0=0.0, degree=3, epsilon=2, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=20, cache_size=200, coef0=0.0, degree=3, epsilon=2, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
MAE: 13.561
MAPE: inf
Accuracy = -inf%
RMSE (test): 18.2372512514
RMSE (train): 13.5559191724
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    212     # data.to_csv(csv_file_path, index=False)
    213
--> 214     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    149
    150
--> 151     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    152                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    153                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [113]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
********************
best params: {'svr__C': 50, 'svr__epsilon': 5, 'svr__kernel': 'rbf'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=50, cache_size=200, coef0=0.0, degree=3, epsilon=5, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=50, cache_size=200, coef0=0.0, degree=3, epsilon=5, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
MAE: 12.835
MAPE: inf
Accuracy = -inf%
RMSE (test): 17.403930849
RMSE (train): 10.7064744006
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    212     # data.to_csv(csv_file_path, index=False)
    213
--> 214     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    149
    150
--> 151     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    152                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    153                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [114]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
********************
best params: {'svr__C': 100, 'svr__epsilon': 5, 'svr__kernel': 'rbf'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=5, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=100, cache_size=200, coef0=0.0, degree=3, epsilon=5, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
MAE: 13.270
MAPE: inf
Accuracy = -inf%
RMSE (test): 17.7243614445
RMSE (train): 9.32728317293
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    212     # data.to_csv(csv_file_path, index=False)
    213
--> 214     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    149
    150
--> 151     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    152                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    153                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [115]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
********************
best params: {'svr__C': 200, 'svr__epsilon': 2, 'svr__kernel': 'rbf'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=200, cache_size=200, coef0=0.0, degree=3, epsilon=2, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=200, cache_size=200, coef0=0.0, degree=3, epsilon=2, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
MAE: 14.662
MAPE: inf
Accuracy = -inf%
RMSE (test): 18.6148038111
RMSE (train): 7.3087268561
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    212     # data.to_csv(csv_file_path, index=False)
    213
--> 214     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    149
    150
--> 151     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    152                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    153                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [116]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
********************
best params: {'svr__C': 200, 'svr__epsilon': 2, 'svr__kernel': 'rbf'}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=200, cache_size=200, coef0=0.0, degree=3, epsilon=2, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('svr', SVR(C=200, cache_size=200, coef0=0.0, degree=3, epsilon=2, gamma='auto',
  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False))])
MAE: 14.662
MAPE: inf
Accuracy = -inf%
RMSE (test): 18.6148038111
RMSE (train): 7.3087268561
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    212     # data.to_csv(csv_file_path, index=False)
    213
--> 214     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    149
    150
--> 151     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    152                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    153                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [117]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 17.100
MAPE: inf
Accuracy = -inf%
RMSE (test): 19.8621556288
RMSE (train): 19.9171255207
Underfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    212     # data.to_csv(csv_file_path, index=False)
    213
--> 214     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    149
    150
--> 151     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    152                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    153                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [118]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
y_train: 160     3.921000
127     5.511000
169    12.151000
188     4.700000
187    12.200000
192    17.000000
62     91.831000
141     0.000000
183     6.221000
37     74.128767
50     74.000000
89     52.560000
107    72.105000
152    10.431000
163     3.911000
24     52.366667
116    39.820000
148     9.101000
33     49.100000
23     73.900000
136     8.281000
125     9.661000
41     34.964748
168    14.301000
85     13.601000
81     54.846000
93     44.732000
100    50.651000
77     57.007000
82     61.328000
         ...
182    16.391000
206     7.600000
39     41.594643
84     55.272000
2      57.622222
55     49.257143
49     66.400000
68     53.588000
199     6.800000
164     5.861000
78     56.377000
203     9.100000
153     0.000000
111    55.227000
174     3.781000
32     77.520635
73     40.354000
47     62.410714
207     3.600000
113    21.589000
96     45.530000
57     52.366000
123     7.841000
106    39.154000
83     34.816000
17     56.225995
98     67.092000
66     24.900000
126     5.091000
109    36.179000
Name: asthma_rate, Length: 167, dtype: float64
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 17.100
MAPE: inf
Accuracy = -inf%
RMSE (test): 19.8621556288
RMSE (train): 19.9171255207
Underfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    213     # data.to_csv(csv_file_path, index=False)
    214
--> 215     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    150
    151
--> 152     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    153                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    154                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [119]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (167, 20)
y_train.shape (167,)
X_test.shape (42, 20)
y_test.shape (42,)
y_train zeros: 141    0.0
142    0.0
149    0.0
153    0.0
Name: asthma_rate, dtype: float64
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 17.100
MAPE: inf
Accuracy = -inf%
RMSE (test): 19.8621556288
RMSE (train): 19.9171255207
Underfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    213     # data.to_csv(csv_file_path, index=False)
    214
--> 215     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    150
    151
--> 152     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    153                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    154                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [120]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (164, 20)
y_train.shape (164,)
X_test.shape (41, 20)
y_test.shape (41,)
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 1}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=1,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=1,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 17.590
MAPE: inf
Accuracy = -inf%
RMSE (test): 21.5097827885
RMSE (train): 19.278485703
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    213     # data.to_csv(csv_file_path, index=False)
    214
--> 215     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    150
    151
--> 152     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    153                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    154                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [121]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (164, 20)
y_train.shape (164,)
X_test.shape (41, 20)
y_test.shape (41,)
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: 158    0.0
Name: asthma_rate, dtype: float64
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 1}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=1,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=1,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 17.590
MAPE: inf
Accuracy = -inf%
RMSE (test): 21.5097827885
RMSE (train): 19.278485703
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    214     # data.to_csv(csv_file_path, index=False)
    215
--> 216     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    151
    152
--> 153     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    154                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    155                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [122]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:250: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator
  self._final_estimator.fit(Xt, y, **fit_params)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:477: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.
  positive)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 18.134
MAPE: 171.376
Accuracy = -71.376%
RMSE (test): 21.5459799984
RMSE (train): 19.4746340169
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    214     # data.to_csv(csv_file_path, index=False)
    215
--> 216     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    151
    152
--> 153     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    154                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    155                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [123]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 18.134
MAPE: 171.376
Accuracy = -71.376%
RMSE (test): 21.5459799984
RMSE (train): 19.4746340169
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    214     # data.to_csv(csv_file_path, index=False)
    215
--> 216     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    151
    152
--> 153     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    154                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    155                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [124]: run models.py
  File "/Users/howard/workspace/dsi/capstone/capstone_repo/src/models.py", line 107
    'elasticnet__max_iter': [10000]
                         ^
SyntaxError: invalid syntax


In [125]: run models.py
  File "/Users/howard/workspace/dsi/capstone/capstone_repo/src/models.py", line 107
    'elasticnet__max_iter': [10000],
                         ^
SyntaxError: invalid syntax


In [126]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.8, 'elasticnet__max_iter': 10000}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=10000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.8,
      max_iter=10000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 18.134
MAPE: 171.376
Accuracy = -71.376%
RMSE (test): 21.5459799984
RMSE (train): 19.4746340169
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    215     # data.to_csv(csv_file_path, index=False)
    216
--> 217     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    152
    153
--> 154     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    155                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    156                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

NameError: name 'tag' is not defined

In [127]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/howard/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
^C^[[A---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    215     # data.to_csv(csv_file_path, index=False)
    216
--> 217     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    131         clf = GridSearchCV(pipeline, hyperparameters, cv=3) # cv=3 is same as cv=None (default)
    132
--> 133         clf.fit(X_train, y_train)
    134
    135         # evaluate models with test data

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self, X, y, groups, **fit_params)
    637                                   error_score=self.error_score)
    638           for parameters, (train, test) in product(candidate_params,
--> 639                                                    cv.split(X, y, groups)))
    640
    641         # if one choose to see train score, "out" will contain train score info

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    777             # was dispatched. In particular this covers the edge
    778             # case of Parallel used with an exhausted iterator.
--> 779             while self.dispatch_one_batch(iterator):
    780                 self._iterating = True
    781             else:

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self, iterator)
    623                 return False
    624             else:
--> 625                 self._dispatch(tasks)
    626                 return True
    627

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self, batch)
    586         dispatch_timestamp = time.time()
    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
--> 588         job = self._backend.apply_async(batch, callback=cb)
    589         self._jobs.append(job)
    590

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self, func, callback)
    109     def apply_async(self, func, callback=None):
    110         """Schedule a func to be run"""
--> 111         result = ImmediateResult(func)
    112         if callback:
    113             callback(result)

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self, batch)
    330         # Don't delay the application, to avoid keeping the input
    331         # arguments in memory
--> 332         self.results = batch()
    333
    334     def get(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)
    456             estimator.fit(X_train, **fit_params)
    457         else:
--> 458             estimator.fit(X_train, y_train, **fit_params)
    459
    460     except Exception as e:

~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self, X, y, **fit_params)
    248         Xt, fit_params = self._fit(X, y, **fit_params)
    249         if self._final_estimator is not None:
--> 250             self._final_estimator.fit(Xt, y, **fit_params)
    251         return self
    252

~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py in fit(self, X, y, check_input)
    750                           random_state=self.random_state,
    751                           selection=self.selection,
--> 752                           check_input=False)
    753             coef_[k] = this_coef[:, 0]
    754             dual_gaps_[k] = this_dual_gap[0]

~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py in enet_path(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)
    475             model = cd_fast.enet_coordinate_descent(
    476                 coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random,
--> 477                 positive)
    478         else:
    479             raise ValueError("Precompute should be one of True, False, "

KeyboardInterrupt:

In [128]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
********************
best params: {'elasticnet__alpha': 1, 'elasticnet__l1_ratio': 0.9, 'elasticnet__max_iter': 10000}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.9,
      max_iter=10000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('elasticnet', ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.9,
      max_iter=10000, normalize=False, positive=False, precompute=False,
      random_state=None, selection='cyclic', tol=0.0001, warm_start=False))])
MAE: 17.773
MAPE: 166.012
Accuracy = -66.012%
RMSE (test): 21.3832428556
RMSE (train): 19.2407232728
Overfit
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    215     # data.to_csv(csv_file_path, index=False)
    216
--> 217     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    152
    153
--> 154     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    155                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    156                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

KeyError: 'rfr'

In [129]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
^C---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    215     # data.to_csv(csv_file_path, index=False)
    216
--> 217     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    131         clf = GridSearchCV(pipeline, hyperparameters, cv=3) # cv=3 is same as cv=None (default)
    132
--> 133         clf.fit(X_train, y_train)
    134
    135         # evaluate models with test data

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self, X, y, groups, **fit_params)
    637                                   error_score=self.error_score)
    638           for parameters, (train, test) in product(candidate_params,
--> 639                                                    cv.split(X, y, groups)))
    640
    641         # if one choose to see train score, "out" will contain train score info

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    777             # was dispatched. In particular this covers the edge
    778             # case of Parallel used with an exhausted iterator.
--> 779             while self.dispatch_one_batch(iterator):
    780                 self._iterating = True
    781             else:

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self, iterator)
    623                 return False
    624             else:
--> 625                 self._dispatch(tasks)
    626                 return True
    627

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in _dispatch(self, batch)
    586         dispatch_timestamp = time.time()
    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)
--> 588         job = self._backend.apply_async(batch, callback=cb)
    589         self._jobs.append(job)
    590

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self, func, callback)
    109     def apply_async(self, func, callback=None):
    110         """Schedule a func to be run"""
--> 111         result = ImmediateResult(func)
    112         if callback:
    113             callback(result)

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self, batch)
    330         # Don't delay the application, to avoid keeping the input
    331         # arguments in memory
--> 332         self.results = batch()
    333
    334     def get(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0)
    129
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
    132
    133     def __len__(self):

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)
    456             estimator.fit(X_train, **fit_params)
    457         else:
--> 458             estimator.fit(X_train, y_train, **fit_params)
    459
    460     except Exception as e:

~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self, X, y, **fit_params)
    248         Xt, fit_params = self._fit(X, y, **fit_params)
    249         if self._final_estimator is not None:
--> 250             self._final_estimator.fit(Xt, y, **fit_params)
    251         return self
    252

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in fit(self, X, y, sample_weight, monitor)
   1032         # fit the boosting stages
   1033         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,
-> 1034                                     begin_at_stage, monitor, X_idx_sorted)
   1035         # change shape of arrays after fit (early-stopping or additional ests)
   1036         if n_stages != self.estimators_.shape[0]:

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stages(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)
   1087             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,
   1088                                      sample_mask, random_state, X_idx_sorted,
-> 1089                                      X_csc, X_csr)
   1090
   1091             # track deviance (= loss)

~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py in _fit_stage(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)
    786             else:
    787                 tree.fit(X, residual, sample_weight=sample_weight,
--> 788                          check_input=False, X_idx_sorted=X_idx_sorted)
    789
    790             # update tree leaves

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self, X, y, sample_weight, check_input, X_idx_sorted)
   1122             sample_weight=sample_weight,
   1123             check_input=check_input,
-> 1124             X_idx_sorted=X_idx_sorted)
   1125         return self
   1126

~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py in fit(self, X, y, sample_weight, check_input, X_idx_sorted)
    360                                            min_impurity_split)
    361
--> 362         builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)
    363
    364         if self.n_outputs_ == 1:

KeyboardInterrupt:

In [130]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
********************
best params: {'gradientboostingregressor__learning_rate': 0.1, 'gradientboostingregressor__loss': 'ls', 'gradientboostingregressor__max_depth': 5, 'gradientboostingregressor__min_samples_split': 10, 'gradientboostingregressor__n_estimators': 800}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=5, max_features=None,
             max_leaf_nodes=None, mi...s=800, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=5, max_features=None,
             max_leaf_nodes=None, mi...s=800, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))])
MAE: 13.477
MAPE: 130.426
Accuracy = -30.426%
RMSE (test): 19.1532978179
RMSE (train): 0.000315904360054
Overfit
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    215     # data.to_csv(csv_file_path, index=False)
    216
--> 217     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    152
    153
--> 154     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    155                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    156                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

KeyError: 'rfr'

In [131]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
********************
best params: {'gradientboostingregressor__learning_rate': 0.1, 'gradientboostingregressor__loss': 'ls', 'gradientboostingregressor__max_depth': 3, 'gradientboostingregressor__min_samples_split': 10, 'gradientboostingregressor__n_estimators': 700}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, mi...s=700, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, mi...s=700, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))])
MAE: 14.308
MAPE: 140.372
Accuracy = -40.372%
RMSE (test): 20.1679284739
RMSE (train): 0.0484753247806
Overfit
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    215     # data.to_csv(csv_file_path, index=False)
    216
--> 217     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    152
    153
--> 154     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    155                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    156                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

KeyError: 'rfr'

In [132]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
********************
best params: {'gradientboostingregressor__learning_rate': 0.1, 'gradientboostingregressor__loss': 'ls', 'gradientboostingregressor__max_depth': 3, 'gradientboostingregressor__min_samples_split': 10, 'gradientboostingregressor__n_estimators': 700}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, mi...s=700, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('gradientboostingregressor', GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, mi...s=700, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False))])
MAE: 14.389
MAPE: 141.552
Accuracy = -41.552%
RMSE (test): 20.2074564398
RMSE (train): 0.0484753247806
Overfit
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    215     # data.to_csv(csv_file_path, index=False)
    216
--> 217     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    152
    153
--> 154     mod = RFR(  max_features        = best_params_dict[tag]['randomforestregressor__max_features'],
    155                 max_depth           = best_params_dict[tag]['randomforestregressor__max_depth'],
    156                 bootstrap           = best_params_dict[tag]['randomforestregressor__bootstrap'],

KeyError: 'rfr'

In [133]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
********************
best params: {}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])
MAE: 17.610
MAPE: 148.307
Accuracy = -48.307%
RMSE (test): 22.3667600731
RMSE (train): 18.2558759049
Overfit
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
~/workspace/dsi/capstone/capstone_repo/src/models.py in <module>()
    215     # data.to_csv(csv_file_path, index=False)
    216
--> 217     all_regress(data)

~/workspace/dsi/capstone/capstone_repo/src/models.py in all_regress(data)
    160
    161
--> 162     mod.fit(X_train, y_train)
    163     print('get_params()'*20)
    164     print(mod.get_params())

NameError: name 'mod' is not defined

In [134]: run models.py
Data file found, loading data...
SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE SHAPE
X_train.shape (163, 20)
y_train.shape (163,)
X_test.shape (41, 20)
y_test.shape (41,)
MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL MODEL
<class 'sklearn.ensemble.forest.RandomForestRegressor'>
rfr
y_train zeros: Series([], Name: asthma_rate, dtype: float64)
y_test zeros: Series([], Name: asthma_rate, dtype: float64)
********************
best params: {}
best grid: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])
^^^^^^^^^^^^^^^^^^^^
Model Performance Indicators
Model: Pipeline(memory=None,
     steps=[('standardscaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linearregression', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])
MAE: 17.610
MAPE: 148.307
Accuracy = -48.307%
RMSE (test): 22.3667600731
RMSE (train): 18.2558759049
Overfit
                            OLS Regression Results
==============================================================================
Dep. Variable:            asthma_rate   R-squared:                       0.523
Model:                            OLS   Adj. R-squared:                  0.456
Method:                 Least Squares   F-statistic:                     7.783
Date:                Fri, 06 Apr 2018   Prob (F-statistic):           1.15e-14
Time:                        10:35:29   Log-Likelihood:                -704.72
No. Observations:                 163   AIC:                             1451.
Df Residuals:                     142   BIC:                             1516.
Df Model:                          20
Covariance Type:            nonrobust
===================================================================================
                      coef    std err          t      P>|t|      [0.025      0.975]
-----------------------------------------------------------------------------------
const              52.8810     13.341      3.964      0.000      26.508      79.254
pm10_mean           0.7096      0.193      3.673      0.000       0.328       1.092
pm25_mean           0.4762      0.906      0.525      0.600      -1.315       2.268
pm25non_mean       -0.8383      0.519     -1.614      0.109      -1.865       0.188
pm25spec_mean      -0.0238      0.018     -1.312      0.192      -0.060       0.012
co_mean            34.8866     21.953      1.589      0.114      -8.510      78.284
so2_mean            0.4973      5.529      0.090      0.928     -10.432      11.427
no2_mean           -0.4810      2.357     -0.204      0.839      -5.140       4.178
ozo_mean          -86.5897    119.261     -0.726      0.469    -322.346     149.166
nonox_mean          0.3789      1.739      0.218      0.828      -3.058       3.816
lead_mean        -260.3690    344.093     -0.757      0.450    -940.576     419.838
haps_mean         -17.3970      7.534     -2.309      0.022     -32.291      -2.503
vocs_mean           0.8342      0.319      2.612      0.010       0.203       1.465
smoke_adult         0.8583      0.853      1.006      0.316      -0.828       2.545
obese_adult        -1.4356      0.473     -3.038      0.003      -2.370      -0.501
uninsured          -2.3704      0.492     -4.814      0.000      -3.344      -1.397
pcp                -0.1187      0.064     -1.866      0.064      -0.245       0.007
high_sch_grad      -0.1864      0.065     -2.875      0.005      -0.314      -0.058
unemployment        3.8619      0.840      4.598      0.000       2.202       5.522
income_ineq         5.4272      2.850      1.904      0.059      -0.208      11.062
air_poll_partic     1.5807      1.316      1.201      0.232      -1.021       4.182
==============================================================================
Omnibus:                        2.344   Durbin-Watson:                   2.056
Prob(Omnibus):                  0.310   Jarque-Bera (JB):                2.306
Skew:                           0.287   Prob(JB):                        0.316
Kurtosis:                       2.899   Cond. No.                     3.70e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 3.7e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

In [135]:
